{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ccc08ee99234c2faffb73cbb140890d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db33d2b5a2443939da0d6e35e25ff7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2a1e41d14c44f883d7b708d434bff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5b556cc8a247199ab9a8fb1153349c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fdb6b3ba4de4c18a96cc4b9edc8fc10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5e985dbf8f435a88e583a01d64c854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e7c06ddfe94e9a95d0c85b0e8aae40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install required libraries\n",
    "# pip install datasets transformers torch flask\n",
    "\n",
    "# Import necessary libraries\n",
    "import re\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Load IMDb dataset\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Extract data\n",
    "X_train = dataset['train']['text']\n",
    "y_train = dataset['train']['label']\n",
    "X_test = dataset['test']['text']\n",
    "y_test = dataset['test']['label']\n",
    "\n",
    "# Preprocess text function\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'<.*?>', ' ', text)  # Remove HTML tags\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    stop_words = set(stopwords.words('english'))  # Stopword removal\n",
    "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    ps = PorterStemmer()\n",
    "    tokens = [ps.stem(word) for word in tokens]  # Stemming\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train = [preprocess_text(review) for review in X_train]\n",
    "X_test = [preprocess_text(review) for review in X_test]\n",
    "\n",
    "# Convert text data into numerical form using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "Accuracy: 0.8776\n",
      "Precision: 0.8758560280299411\n",
      "Recall: 0.87992\n",
      "F1-Score: 0.8778833107191316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model_lr = LogisticRegression(max_iter=1000,penalty='l2', C=1.0)\n",
    "model_lr.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_lr = model_lr.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "precision = precision_score(y_test, y_pred_lr)\n",
    "recall = recall_score(y_test, y_pred_lr)\n",
    "f1 = f1_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the Logistic Regression model and TF-IDF vectorizer\n",
    "joblib.dump(model_lr, 'model_lr.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
